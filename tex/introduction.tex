\section{Introduction}
\label{introduction}

Various types of graphs are commonly used as models for real-world phenomenon, such as online social networks, biological networks, the world wide web, among others. As their sizes keep increasing, scaling up algorithms to handle extreme size graphs with billions of vertices and edges remains a challenge that has drawn increased attention in recent years. Specifically, straightforward operations in graph theory are usually too slow or costly when they are applied to graphs at this scale. One problem that has drawn a lot of attention in the past is finding shortest paths in the network. This operation serves as the building block for many other tasks. For example, a natural application for road network is providing driving directions \cite{Abraham:2011:HLA:2008623.2008645}. In social networks, such applications include social sensitive search \cite{Vieira:2007:ESR:1321440.1321520}, analyzing influential people \cite{Kempe:2003:MSI:956750.956769}, among others. Estimating minimum round trip time between hosts without direct measurement is another application in technology networks \cite{Tang:2003:VLI:948205.948223}.

Although previous works have studied shortest path problem on large road networks extensively and have very effective approaches, a large category of networks known as the complex networks has very different structures. Approaches that worked on road networks do not perform well on complex networks, as the latter follow power law degree distributions and small diameters. In this paper, we are focusing on the shortest path problem for complex networks in particular, as their extreme sizes and unique topologies make the problem particularly challenging.

%A straight-forward solution to this problem in complex networks is to apply online traversals like breadth first search or Dijkstra algorithm for each query. But this approach is very inefficient for large scale networks. The $O(|E|)$ time complexity and $O(|V|)$ space complexity make each search very costly. Another obvious solution is to trade space with time, by performing all-pair shortest path operations offline, and storing the results for each pair of vertices for table lookups. However, the cubic time and quadratic space complexity for preprocessing are not acceptable for large scale networks either. Nevertheless, using offline preprocessing to speed up online queries is suitable for most applications.

Our design is motivated by recent studies that combine both offline processing and online queries \cite{Potamias:2009:FSP:1645953.1646063}, \cite{tretyakov2011fast}, \cite{Akiba:2012:SQC:2247596.2247614}, \cite{6399472}, \cite{Jin:2012:HLA:2213836.2213887}. In these methods, the step of preprocessing aims to construct indexes for the networks, which are later used in the online query phase to dramatically reduce the query time. Among these approaches, landmark based algorithms \cite{Thorup:2005:ADO:1044731.1044732}, \cite{Goldberg:2005:CSP:1070432.1070455}, \cite{Potamias:2009:FSP:1645953.1646063}, \cite{Gubichev:2010:FAE:1871437.1871503}, \cite{tretyakov2011fast}, \cite{6399472}are widely used for approximate shortest path/distance between vertices. Usually such algorithms select a small set of landmarks, and construct an index that consists of labels for each vertex, that store distances or shortest paths to landmarks. The approximation accuracy of landmark based algorithms heavily depends on the number of landmarks. Usually to achieve high accuracy, a relatively large set of landmarks is required, which lead to large preprocessing overheads. Indexes that can answer path queries usually have much larger space overhead than indexes that can only answer distance queries. One goal of our design, therefore, is to provide accurate results while still maintain low overhead for indexing.

Previous work also combined online search with index, but most efforts are solely based on the label of source and target vertices, which result in estimated paths only containing vertices belonging to the either label. This problem limits both the accuracy of the estimated path length compare to the exact ones, and the path diversity. So instead of estimating shortest path solely by examining vertices contained in labels of source and target vertices, our algorithm performs a heuristic search on each vertex it examined and pick the next vertex to examine by the distance information gathered during the examine. In this way, our approach explore edges that have not been indexed and examine vertices that does not include3d in labels of source and target vertices to achieve higher accuracy with limited index size. The heuristic search that we use is called decentralized search which was introduced by \cite{Kleinberg:2000p5066}. Here the ``decentralized'' means that the decision at each step is made based solely on local information which, in our context, is the labels of neighbor vertices.

We also introduce several optimizations to control the expansion of search space of decentralized search to balance between different level of accuracies and resources required for each search. With these optimizations, our algorithm becomes more versatile to meet various application needs without redoing the preprocessing.  

On the core of decentralized search, all decisions made at each step relies on information stored in the index, not all the edges are equally important for estimating the shortest paths. To find out which edges should be stored in the index, we introduce a heuristic index construction algorithm that can increase the approximation accuracy by admitting only those most valuable edges. Experimental results shows that our approach not only increase accuracy of decentralized search under same number of landmarks, but also increase the accuracy of other methods based on landmark methods.

[ talk about how the distributed search can help in reduce average query time and can deal with very large scale networks]
Decentralized search is very light-weighted. The number of visited vertices for decentralized search is bounded by the diameter of the network. Considering that complex networks have relatively a short diameter, decentralized search can finish in very limited steps. Also, the algorithm does not need to mark which vertices have been visited like BFS or A* search, so only small space overhead is required for each search. This property makes it possible for large number of searches running in parallel without reaching the memory limit of machines. For example, in our experiments, we showed that millions of decentralized search can run in parallel. Furthermore, the average search time can be controlled at tens of microseconds or even shorter. 

Based on our algorithm design, we further develop a query-processing platform based on distributed cloud infrastructure. In this platform, users first submit their graphs for preprocessing needs. The graph processing engine will assign resources according to application's need for accuracy and construct an index for the input graph. Later, users may submit large volumes of queries repeatedly, for which responses will be generated. The light-weighted decentralized search allows a large amount of queries to run in parallel so that queries can be answered in a timely manner. Applications that generate queries (on the client side) can provide their desired accuracy levels and the graph processing engine can dynamically adjust search space of decentralized search to meet differentiated levels of accuracies.


\subsection{Contributions}
Our contributions can be summarized as follows:

First, as an approximation algorithm, we combine decentralized search with landmark based indexes to achieve a high level of accuracy. We optimize the search space of decentralized search to achieve low online search overheads. By controlling the search space, our algorithm is able to achieve differentiated levels of accuracies.

Second, we propose a more effective heuristic approach for constructing index of the network that can improve the accuracy of the decentralized search without increasing preprocessing and online search overheads.

Third, we implement our algorithm in a distributed manner to handle extremely large graphs and perform the decentralized search in a parallel way to further reduce the average online query time for better scalability.

The rest of this paper is organized as follows. In Section \ref{preliminary}, we give notations and definitions used in this paper. We explain decentralized search for shortest path approximation in Section \ref{searching}. Section \ref{preprocessing} shows our index construction algorithm. In Section \ref{implementation} we show details on our distributed implementation. And we show the evaluations of our algorithm in Section \ref{evaluation}. In Section \ref{relatedwork} we described previous works on exact and approximate approaches. We conclude our work in Section \ref{conclusion}.
