\section{Introduction}
\label{introduction}

Various types of graphs are commonly used as models for real-world phenomenon, such as online social networks, biological networks, the world wide web, among others. As their sizes keep increasing, scaling up algorithms to handle extreme size graphs with billions of vertices and edges remains a challenge that has drawn increased attention in recent years. Specifically, straightforward operations in graph theory are usually too slow or costly when they are applied to graphs at this scale. One problem that has drawn a lot of attention in the past is finding shortest paths in the network. This operation serves as the building block for many other tasks. For example, a natural application for road network is providing driving directions \cite{Abraham:2011:HLA:2008623.2008645}. In social networks, such applications include social sensitive search \cite{Vieira:2007:ESR:1321440.1321520}, analyzing influential people \cite{Kempe:2003:MSI:956750.956769}, among others. Estimating minimum round trip time between hosts without direct measurement is another application in technology networks \cite{Tang:2003:VLI:948205.948223}.

Although previous works have studied shortest path problem on large road networks extensively and have very effective approaches, a large category of networks known as the complex networks has very different structures. Approaches that worked on road networks do not perform well on complex networks, as the latter follow power law degree distributions and small diameters. In this paper, we are focusing on the shortest path problem for complex networks in particular, as their extreme sizes and unique topologies make the problem particularly challenging.

Our design is motivated by recent studies that combine both offline processing and online queries \cite{Potamias:2009:FSP:1645953.1646063, tretyakov2011fast, Akiba:2012:SQC:2247596.2247614, 6399472, Jin:2012:HLA:2213836.2213887}. In these methods, the step of preprocessing aims to construct indexes for the networks, which are later used in the online query phase to dramatically reduce the query time. Among these approaches, landmark based algorithms \cite{Thorup:2005:ADO:1044731.1044732, Goldberg:2005:CSP:1070432.1070455, Potamias:2009:FSP:1645953.1646063, Gubichev:2010:FAE:1871437.1871503, tretyakov2011fast, 6399472}are widely used for approximate shortest path/distance between vertices. Usually such algorithms select a small set of landmarks, and construct an index that consists of labels for each vertex, that store distances or shortest paths to landmarks. The approximation accuracy of landmark based algorithms heavily depends on the number of landmarks. Usually to achieve high accuracy, a relatively large set of landmarks is required, which lead to large preprocessing overheads. Indexes that can answer path queries usually have much larger space overhead than indexes that can only answer distance queries. One goal of our design, therefore, is to provide accurate results while still maintain low overhead for indexing.

Previous works that combie online search with index only explore short cuts among vertices between label of source and target vertices ~\cite{Gubichev:2010:FAE:1871437.1871503, 6399472}. The accuracy and path diversity are rather limited this way. Instead of estimating shortest path solely by examining vertices contained in labels of source and target vertices, our algorithm performs a heuristic search on each vertex it visited and pick the vertex to visit in next step by the distance information gathered from neighbor vertices of current step. Our approach is able to explore edges that have not been indexed and examine vertices that does not included in labels of source and target vertices to achieve higher accuracy and path diversity with limited index size. The heuristic search that we use is called decentralized search which was introduced by \cite{Kleinberg:2000p5066}. Here the "`decentralized"' means that the decision at each step is made based solely on local information which, in our context, is the labels of neighbor vertices.

%The number of visited vertices for decentralized search is bounded by the diameter of the network. Considering that complex networks have relatively a short diameter, decentralized search can finish in very limited steps. 
Decentralized search can expand its search space to balance between different level of performance, i.e. accuracy and path diversity, and resources required for each search. The search is very versatile to meet various application needs without redoing the preprocessing.  

The performance of decentralized search relies heavily on the index. To achieve better accuracy without increase index overhead, we introduce a heuristic index construction algorithm to control shortest paths to be indexed during preprocessing. 

We implement decentralized search on a distributed platform to support large scale graph with billions of edges. To take advantage of resources available for a cluster of machines, our algorithm can support large amount of queries to run in parallel. There are two properties of decentralized search which makes it very suitable for parallel processing. First, decentralized search is very light-weighted in terms of space complexity and communication complexity. The search does not need to store any information on a per vertex basis like BFS or A* search, very limited space overhead is required for each search. Second, decentralized search does not have data dependency on the index and underlying graph. Multiple search can run independently on the same graph and index. These properties makes it possible for large number of searches running in parallel efficiently without reaching the physical limit of machines, i.e. memory limit or network bandwidth. For example, in our experiments, we showed that millions of decentralized search can run in parallel on graphs with billions of edges on a cluster of commodity machines, and finish in tens of seconds. 

Based on our algorithm design, we further develop a query-processing system based on distributed cloud infrastructure. In this platform, users first submit their graphs for preprocessing needs. The graph processing engine will assign resources according to application's need for accuracy and construct an index for the input graph. Later, users may submit large volumes of queries repeatedly, for which responses will be generated. The light-weighted decentralized search allows a large amount of queries to run in parallel so that queries can be answered in a timely manner. Applications that generate queries (on the client side) can provide their desired accuracy levels and the graph processing engine can dynamically adjust search space of decentralized search to meet differentiated levels of accuracies.

\subsection{Contributions}
Our contributions can be summarized as follows:

\begin{itemize}
	\item We propose index guided decentralized search for shortest path approximation;
	\item We design a heuristic index construction algorithm that can improve accuracy of the decentralized search without increasing preprocessing or online search overheads.
	\item We achieve efficient query processing and good scalability with implementations in distributed settings and parallel processing.
	\item Experiments on various complex networks demonstrate that the proposed algorithm is promising in approximating shortest path compared to existing works.
\end{itemize}

The rest of this paper is organized as follows. In Section \ref{preliminary}, we give notations and definitions used in this paper. We explain decentralized search for shortest path approximation in Section \ref{searching}. Section \ref{preprocessing} shows our index construction algorithm. In Section \ref{implementation} we show details on our distributed implementation. And we show the evaluations of our algorithm in Section \ref{evaluation}. In Section \ref{relatedwork} we described previous works on exact and approximate approaches. We conclude our work in Section \ref{conclusion}.
