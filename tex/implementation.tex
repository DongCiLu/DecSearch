\section{Distributed Implementations}
\label{implementation}

To handle extremely large graphs, we implement our algorithm in distributed settings. Due to that decentralized search does not require large volume of data to be cached during the search, it is well suitable for running in a parallel way. Our implementations can handle graphs with billions of edges and running millions of independent queries in parallel.

We build our algorithm on a distributed general graph processing platform - Powergraph\cite{180251}. An overview of our system is shown in Fig. \ref{fig:system}. Powergraph is designed to handle large-scale graphs with power law degree distributions efficiently by taking advantage of vertex-programs to factor computation over edges. Computation in Powergraph consists of a vertex-program running on a set of vertices. Each vertex-program consist of three phases: Gather, Apply and Scatter. During Gather phase, the $gather$ and $sum$ functions are used to collect and accumulate data from neighbors. The vertex data is updated in Apply phase by $apply$ function through analysis on data collected from Gather phase. In the Scatter phase, $scatter$ function is used to spread the new value to the graph and signal neighbors to start new vertex-programs. In this section, we are going to talk about details on how we implement our algorithm as vertex-programs.

\subsection{Decentralized search vertex-program}

Algorithm \ref{alg:vc_dec} shows the vertex-program of decentralized search. In Gather phase, for each query, LCA distance $d_L$ calculated from labels $L$ of each neighbor and target vertex is collected and accumulated by finding the neighbor with the smallest LCA distance. If a tie happens, according to our tie strategy, multiple neighbors may be returned as candidates. Since the decentralized search is a state-less search itself, vertex data does not need to be updated during the Apply phase. Instead, the program will append the candidate(s) to the approximated path $p_{appr.}$ and check whether the stop criterion is satisfied for each query. If so, the results will be recorded and this query will be terminated. Otherwise, program will proceed to Scatter phase to start new vertex-programs on next hop candidate(s) of each query and pass query information to them.

\begin{algorithm}
    \caption{Algorithm decentralized search vertex program running on $u$}
		\label{alg:vc_dec}
    \begin{algorithmic}
        \Function{gather}{$L(v)$, $L(t)$}
        %\Comment {Collect LCA distances from Nbrs}
        \State \Return $d_L(v, t)$
        \EndFunction

        \Function{sum}{$d_L(v_1,t)$, $d_L(v_2,t)$}
        %\Comment {Find Nbr with smallest LCA distance to target}
        \State \Return $min(d_L(v_1,t), d_L(v_2,t)$
        \EndFunction

        \Function{apply}{$p_{appr.}(s,t)$, $d_L(v,t)$}
        %\Comment {Update approximate path and check termination}
        \State $p_{appr.}(s,t) += u$
        \If {termination condition meets}
            \State store $p_{appr.}(s,t)$
            \State $term$ = true
        \Else
            \State $term$ = false
        \EndIf
        \EndFunction

        \Function{scatter}{$p_{appr.}(s,t)$, $term$}
        %\Comment {Signal candidates}
        \If {$\neg term$}
            \State Activate(v, $p_{appr.}(s,t)$)
        \EndIf
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\subsection{Distributed tie breaking strategy}

In the centralized version of our search algorithm, ties can be handled very easily. If a candidate cannot lead to the shortest approximate path at the next step among all candidates, it will be simply discarded. The situation becomes more complicated when implementing decentralized search in a distributed setting. In the distributed version of decentralized search, each candidate will start a new vertex program to approximate shortest path independently. There are no communications among different searches as this would be too costly to implement in a distributed setting. Hence, a candidate does not know the length of the path found by other candidates. Even if a candidate finds a shorter path, it does not have the ability to terminate searches at other candidates.

With this limitation, the search space are quite difficult to control and the search may end up with excessive overhead. A naive to alleviate this problem is to set a hard limit on the number of neighbors selected as candidates for next hop. But the algorithm needs to first decide which ones to select, and there is no available information to help making this decision. Another approach used in our implementation is that at each step, only one candidate will be chosen as a ``main'' candidate. For candidates that are not ``main'' candidates, an extra stop criterion will be applied. If it cannot find a shorter path than the one currently found, then the search will stop, and no result will be recorded. This will certainly reduce the chance a shorter path to be found. But it has a much smaller overhead and treats candidates more adaptively than the hard limit approach.